{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOIyWlLVxafl"
      },
      "outputs": [],
      "source": [
        "#1. Explain the properties of the F-distribution.\n",
        "#Ans: The F-distribution is positively skewed and with the increase in the degrees of freedom ν1 and ν2, its skewness decreases.\n",
        "#The value of the F-distribution is always positive, or zero since the variances are the square\n",
        "#of the deviations and hence cannot assume negative values. Its value lies between 0 and ∞.\n",
        "#The statistic used to calculate the value of mean and variance is:Properties of F-distribution\n",
        "\n",
        "#The shape of the F-distribution depends on its parameters ν1 and ν2 degrees of freedom.\n",
        "#The values of the area lying on the left-hand side of the distribution can be found out by taking the reciprocal of F\n",
        "#values corresponding to the right-hand side and the degrees of freedom in the numerator and the denominator are interchanged.\n",
        "#This is called as Reciprocal Property of F-distribution. Symbolically, it can be represented as:roperties of F-distribution-2\n",
        "#This property is mainly used in the situations when the values of the lower tail F values are to be determined\n",
        "#corresponding to the upper tail F values.\n",
        "Mean = df2 / (df2 - 2) (when df2 > 2)\n",
        "Variance = (2 * (df2^2) * (df1 + df2 - 2)) / (df1 * (df2 - 2)^2 * (df2 - 4)) (when df2 > 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "#Ans:F test is a statistical test that is used in hypothesis testing to check whether the variances of two populations or two samples are\n",
        "#equal or not. In an f test, the data follows an f distribution. This test uses the f statistic to compare two variances by dividing them.\n",
        "#An f test can either be one-tailed or two-tailed depending upon the parameters of the problem.\n",
        "#The f value obtained after conducting an f test is used to perform the one-way ANOVA (analysis of variance) test.\n",
        "#In this article, we will learn more about an f test, the f statistic, its critical value, formula and\n",
        "#how to conduct an f test for hypothesis testing.\n",
        "\n",
        "#F test is statistics is a test that is performed on an f distribution. A two-tailed f test is used to check whether the variances of the\n",
        "#two given samples (or populations) are equal or not. However, if an f test checks whether one population\n",
        "#variance is either greater than or lesser than the other, it becomes a one-tailed hypothesis f test.\n",
        "#F test can be defined as a test that uses the f test statistic to check whether the variances of two samples (or populations) are\n",
        "#equal to the same value. To conduct an f test, the population should follow an f distribution and the samples must be independent events.\n",
        "#On conducting the hypothesis test, if the results of the f test are statistically significant then the null hypothesis can be rejected\n",
        "#otherwise it cannot be rejected.\n",
        "#The f test statistic or simply the f statistic is a value that is compared with the critical value to check if the null hypothesis\n",
        "#should be rejected or not. The f test statistic formula is given below:\n",
        "#Find the degrees of freedom of the first sample. This is done by subtracting 1 from the first sample size. Thus, x = n1−1.\n",
        "#Determine the degrees of freedom of the second sample by subtracting 1 from the sample size. This given y = n2−1.\n",
        "#If it is a right-tailed test then α is the significance level. For a left-tailed test 1 - α\n",
        "#is the alpha level. However, if it is a two-tailed test then the significance level is given by α/2.\n",
        "#The F table is used to find the critical value at the required alpha level.\n",
        "#The intersection of the x column and the y row in the f table will give the f test critical value.\n"
      ],
      "metadata": {
        "id": "RsKOJojy0iz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
        "#Ans:The three main assumptions required to use the F distribution for making inferences about the ratio of population variances are:\n",
        "#1) Independence of the samples, 2) Normality of the populations from which the samples are drawn, and 3) Random sampling of the samples\n",
        "#from their respective populations.\n",
        "#Assumptions for F-test\n",
        "#There are three main assumptions that need to be met for the F distribution to be used in making inferences about the ratio of population variances:\n",
        "#1. Independence: The samples must be independent, meaning that the observations in one sample are not related to the observations in\n",
        "#the second sample. 2. Normality: The populations from which the samples are drawn must be normally distributed. If the sample sizes are\n",
        "#large, this assumption can be relaxed according to the Central Limit Theorem. 3. Random Samples: The samples must be obtained through random\n",
        "#selection from the populations they represent.\n",
        "#Population Variances\n",
        "#In statistics, understanding the variability within a population is crucial. Population variance is a measure of how much the data in a\n",
        "#population is spread out around the mean. It provides insight into the\n",
        "consistency\n",
        "predictability\n",
        "and reliability of a dataset.\n",
        "#If the variance is low, the data points are close to the mean, indicating uniformity across observations. However, a high variance means\n",
        "#that data points are spread out over a larger range of values, suggesting greater diversity or inconsistency within the population.\n",
        "#To study variances between two populations, a common approach is to look at their ratio. This is where the F distribution becomes\n",
        "#particularly useful. By comparing the ratio of two variances, statisticians can make inferences about the differences between populations.\n",
        "#Assumptions of F Distribution\n",
        "#For the F distribution to provide reliable results in hypothesis testing, several key assumptions must be satisfied: - **Independence**:\n",
        "#The samples must be independent of each other. This means that observations in one sample do not affect or influence those in another. -\n",
        "#**Normality**: The populations from which the samples are drawn should be normally distributed. In cases where sample sizes are large,\n",
        "#the central limit theorem may allow for some flexibility on this assumption. - **Random Sampling**: The data must be collected from random\n",
        "#samples to represent the populations accurately. Without randomness, the conclusions drawn could be biased or incorrect.\n",
        "#Only when these assumptions are adequately met, the use of the F distribution in statistical analysis gains validity.\n",
        "#It emphasizes the importance of proper data collection techniques and ensuring that the prerequisites for analysis are fulfilled,\n",
        "#thus making the inferences drawn credible and valuable.\n"
      ],
      "metadata": {
        "id": "CfmiL1u9NFI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "#Ans:Analysis of Variance (ANOVA) is a statistical method commonly used to compare more than two population means, such as evaluating crop\n",
        "#yield from multiple seed varieties. It is an essential tool for researchers, allowing them to conduct simultaneous tests. When employing ANOVA,\n",
        "#it is assumed that the samples are drawn from normally distributed populations with equal population variances.\n",
        "\n",
        "#In ANOVA, the total variation in a dataset is partitioned into two categories: variation due to chance and variation attributed to specific causes.\n",
        "#The underlying principle is to assess the variances among population means by evaluating the variation within groups relative to the variation\n",
        "#between groups. Variance arises within the sample due to random and unexplained disturbances, whereas variations between samples can be attributed\n",
        "#to different treatments.\n",
        "\n",
        "#Using this technique, we can test the null hypothesis (H0), which assumes all population means are equal, or the alternative hypothesis (H1),\n",
        "#which suggests at least one population mean is different.\n",
        "\n",
        "#Understanding the Differences Between ANOVA & T-Test\n",
        "#ANOVA and t-test are statistical methods used to compare means between groups, but they differ in several ways:\n",
        "\n",
        "#Number of Groups\n",
        "#T-tests only compare means between two groups.\n",
        "#ANOVA can compare means among three or more groups.\n",
        "#Variation is considered\n",
        "#T-tests focus on within-group variation, specifically comparing the means of two groups and checking whether they are significantly different.\n",
        "#ANOVA analyses both between-group and within-group variation. It examines whether there is a significant difference in means between three or\n",
        "#more groups and determines whether the observed variation between groups is greater than within groups.\n",
        "#Objective\n",
        "#The t-test is used to determine whether there is a significant difference between the means of the two groups.\n",
        "#ANOVA is used to determine whether there is a significant difference between the means of three or more groups."
      ],
      "metadata": {
        "id": "hC4f1QUhwUQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n",
        "#Ans:We should use ANOVA instead of several t-tests to evaluate the differences in the mean of three or more groups because every time,\n",
        "#we conduct a t-test (between two groups) there is some chance that a Type I error is being made while doing the test.\n",
        "\n",
        "#Use a one-way ANOVA when you have collected data about one categorical independent variable and one quantitative dependent variable.\n",
        "#The independent variable should have at least three levels (i.e. at least three different groups or categories).\n",
        "\n",
        "#ANOVA tells you if the dependent variable changes according to the level of the independent variable. For example:\n",
        "\n",
        "#Your independent variable is social media use, and you assign groups to low, medium, and high levels of social media use to find out if there\n",
        "#is a difference in hours of sleep per night.\n",
        "#Your independent variable is brand of soda, and you collect data on Coke, Pepsi, Sprite, and Fanta to find out if there is a difference\n",
        "#in the price per 100ml.\n",
        "#You independent variable is type of fertilizer, and you treat crop fields with mixtures 1, 2 and 3 to find out\n",
        "#if there is a difference in crop yield.\n",
        "#The null hypothesis (H0) of ANOVA is that there is no difference among group means. The alternative hypothesis (Ha) is that at least one\n",
        "#group differs significantly from the overall mean of the dependent variable.\n",
        "#When it comes to achieving the mean of two or more population groups, ANOVA (Analysis of variance) and t-test are the two best practices preferred.\n",
        "#Although there is a thin line of difference between both of them.\n",
        "\n",
        "#The t-test is conducted when you have to find the population means between two groups. But when there are three or more groups you go for\n",
        "#the ANOVA test.\n",
        "\n",
        "#Both t-test and ANOVA are the statistical methods of testing a hypothesis. And they both share the assumptions:\n",
        "\n",
        "#Sample drawn from the population is normally distributed\n",
        "#Homogeneous variance\n",
        "#Random data sampling\n",
        "#Observations are independent\n",
        "#Dependent variable is measured in ratio or interval levels\n",
        "#This is why most people seem to misinterpret t-tests and Analysis of Variance for each other.\n",
        "\n",
        "#In this article, we are going to see, despite their similarities, how t-tests and ANOVA tests are different from each other by using a\n",
        "#comparison chart to make it simple and understandable."
      ],
      "metadata": {
        "id": "_MPu1xey1d0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n",
        "#Ans:Within-group variation (sometimes called error group or error variance) is a term used in ANOVA tests. It refers to variations\n",
        "#caused by differences within individual groups (or levels).\n",
        "#In other words, not all the values within each group (e.g. means) are the same. These are differences not caused by the independent variable.\n",
        "#Each sample is looked at on its own. In other words, no interactions between samples are considered. For example, let’s say you had four groups,\n",
        "#representing drugs A B C D, with each group composed of 20 people in each group and you’re measuring people’s cholesterol levels.\n",
        "#For within-group variation, you’ll look at variances in cholesterol levels for people in group A, without considering groups B,C, and D.\n",
        "#Then you would look at cholesterol levels for people in group B, without considering groups A,C, and D. And so on.\n",
        "#What is Between-Group Variance?\n",
        "#1. Importance of between-group variance\n",
        "\n",
        "#The between-group variance is a crucial measure in ANOVA because it helps to determine whether differences between groups are significant or not.\n",
        "#If the between-group variance is high, it indicates that there are significant differences between the groups, and the null hypothesis can be\n",
        "#rejected. On the other hand, if the between-group variance is low, it suggests that the differences between the groups are not significant, and\n",
        "#the null hypothesis cannot be rejected.\n",
        "\n",
        "#2. Factors that influence between-group variance\n",
        "\n",
        "#There are several factors that can influence the between-group variance. One of the most important factors is the size of the groups.\n",
        "#Smaller groups tend to have higher between-group variances than larger groups. Another factor is the variability of the data within each group.\n",
        "#If the data within each group is highly variable, it can result in a higher between-group variance.\n",
        "\n",
        "#3. Comparing between-group variance with within-group variance\n",
        "\n",
        "#In ANOVA, the between-group variance is compared with the within-group variance to determine whether there are significant differences between\n",
        "#the groups. The within-group variance is the variation within each group and is calculated by taking the sum of squares of the deviations of each\n",
        "#observation from its group mean. The ratio of the between-group variance to the within-group variance is called the F-statistic, and it is used to\n",
        "#determine whether the differences between the groups are significant or not.\n",
        "\n",
        "#4. Example of between-group variance\n",
        "\n",
        "#Suppose we want to compare the performance of three different groups of students in a math test. The first group consists of students who received\n",
        "#extra tutoring, the second group consists of students who received no extra tutoring, and the third group consists of students who received a\n",
        "#different type of tutoring. We can calculate the between-group variance by subtracting the grand mean of all the groups from the mean of each\n",
        "#group and squaring the result. We can then sum the resulting values and divide by the number of groups minus one. If the resulting value is high,\n",
        "#it indicates that there are significant differences between the groups.\n",
        "\n",
        "#5. Best option for analyzing between-group variance\n",
        "\n",
        "#The best option for analyzing between-group variance depends on the type of data and the research question. If the data is normally distributed\n",
        "#and the groups have equal variances, a parametric test such as a one-way ANOVA can be used. If the data is not normally distributed or the groups\n",
        "#have unequal variances, a non-parametric test such as a Kruskal-Wallis test can be used. It is important to choose the appropriate test to ensure\n",
        "#accurate results.\n",
        "\n",
        "#Between-group variance is an essential measure in ANOVA that helps to determine whether there are significant differences between groups.\n",
        "#It is influenced by factors such as the size of the groups and the variability of the data within each group. It is compared with the within-group\n",
        "#variance to determine whether the differences between the groups are significant or not. The best option for analyzing between-group variance\n",
        "#depends on the type of data and the research question."
      ],
      "metadata": {
        "id": "dRIZoRaM88ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "#Ans:With Bayesian statistics, probabilities are more subjective. In the coin toss example, a Bayesian approach states that the probability of\n",
        "#it landing on heads or tails boils down to your beliefs. You might believe there’s a 50% chance for each outcome, or your confidence in the coin’s\n",
        "#fairness could also influence your answer. According to this statistical approach, once you’ve seen the result, you’d update your beliefs based on\n",
        "#that new information.\n",
        "\n",
        "#The main difference between the two methodologies is how they handle uncertainty. Frequentists rely on long-term frequencies and assume that\n",
        "#probabilities are objective and fixed.\n",
        "#Bayesians embrace subjectivity and the idea that probabilities change based on new information.\n",
        "\n",
        "# Product marketers can use both statistical philosophies to enhance their A/B\n",
        "# testing.\n",
        "\n",
        "#Key takeaways\n",
        "#Frequentist and Bayesian statistics differ in how they interpret probabilities, approach prior beliefs, and update probabilities based on new data.\n",
        "#These are advanced statistical methodologies, but you can use them in your A/B tests without being a data scientist.\n",
        "#The best statistical methodology for your next A/B test will depend on context, sample size, and whether you want to incorporate\n",
        "#prior knowledge or beliefs into your experiments.\n",
        "\n",
        "#Frequentists:  Hypothesis testing\tSet null and alternative hypotheses and use statistical tests to assess evidence against the null.\n",
        "#Bayesians :     Consider prior beliefs when forming hypotheses.\n",
        "\n",
        "#Frequentists:   Probability interpretation\tFrame probability in terms of objective, long-term frequencies.\n",
        "#Bayesians :     Interpret probabilities subjectively and update them as new data is collected.\n",
        "\n",
        "#Frequentists:   Sampling\tEmphasize random sampling and often require fixed sample sizes.\n",
        "#Bayesians:       Can adapt well to varying sample sizes since Bayesians update their beliefs as more data comes in.\n"
      ],
      "metadata": {
        "id": "5TjSXjmYL6E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "#V Profession A: [48, 52, 55, 60, 62'\n",
        "#V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "#incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "#Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "#Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
        "#Ans:"
      ],
      "metadata": {
        "id": "DEDr2o2fMmc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "#average heights between three different regions with the following data1\n",
        "#V Region A: [160, 162, 165, 158, 164'\n",
        "#V Region B: [172, 175, 170, 168, 174'\n",
        "#V Region C: [180, 182, 179, 185, 183'\n",
        "#V Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
        "#V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
        "#Ans:"
      ],
      "metadata": {
        "id": "V3tTdd3bPRUd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}